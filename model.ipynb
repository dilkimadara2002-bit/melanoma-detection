# ================================
# Melanoma Detection with CNN (Folder-based)
# Cleaning → Preprocessing → Training → Evaluation
# ================================

# 1) Imports
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.metrics import classification_report, confusion_matrix

# ----------------
# 2) Paths (Windows - D:\)
# ----------------
file_path   = r"D:/melanoma_cancer_dataset"
train_path  = r"D:/melanoma_cancer_dataset/train"
test_path   = r"D:/melanoma_cancer_dataset/test"

# Handle class folder names (supports 'malignant' or misspelled 'melignant')
benign_train_dir = os.path.join(train_path, "benign")
malig_name = "malignant" if os.path.isdir(os.path.join(train_path, "malignant")) else "melignant"
malig_train_dir = os.path.join(train_path, malig_name)

benign_test_dir = os.path.join(test_path, "benign")
malig_test_dir  = os.path.join(test_path, malig_name)

assert os.path.isdir(benign_train_dir), f"Missing folder: {benign_train_dir}"
assert os.path.isdir(malig_train_dir),  f"Missing folder: {malig_train_dir}"
assert os.path.isdir(benign_test_dir),  f"Missing folder: {benign_test_dir}"
assert os.path.isdir(malig_test_dir),   f"Missing folder: {malig_test_dir}"

CLASSES = ["benign", malig_name]  # keep exact folder names in use

# ----------------
# 3) Basic "Cleaning": sanity checks & class distribution
# ----------------
def count_images(folder):
    counts = {}
    for c in CLASSES:
        d = os.path.join(folder, c)
        if os.path.isdir(d):
            counts[c] = sum([1 for f in os.listdir(d) if f.lower().endswith(('.png','.jpg','.jpeg','.bmp','.gif','.tif','.tiff'))])
        else:
            counts[c] = 0
    return counts

train_counts = count_images(train_path)
test_counts  = count_images(test_path)

print("Train distribution:", train_counts)
print("Test distribution :", test_counts)

plt.figure(figsize=(8,4))
sns.barplot(x=list(train_counts.keys()), y=list(train_counts.values()))
plt.title("Training Data Class Distribution")
plt.ylabel("image count")
plt.show()

# Optional: warn if highly imbalanced
total_train = sum(train_counts.values())
for k,v in train_counts.items():
    if v < 0.1*total_train:
        print(f"WARNING: Class '{k}' has only {v} images ({v/total_train:.1%} of training set). Consider augmentation or adding data.")

# ----------------
# 4) Data generators (preprocessing + augmentation)
# ----------------
IMG_SIZE   = (224, 224)
BATCH_SIZE = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.10,
    height_shift_range=0.10,
    zoom_range=0.20,
    shear_range=0.10,
    horizontal_flip=True,
    fill_mode="nearest"
)
test_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(
    directory=train_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    classes=CLASSES,            # enforce folder order
    class_mode="binary",        # benign=0, malignant/melignant=1
    shuffle=True
)
test_gen = test_datagen.flow_from_directory(
    directory=test_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    classes=CLASSES,
    class_mode="binary",
    shuffle=False               # keep order for evaluation
)

print("Class indices mapping:", train_gen.class_indices)  # {'benign':0, 'malignant|melignant':1}

# ----------------
# 5) Optional class weights for imbalance
# ----------------
# Compute inverse-frequency weights
cw = None
if all(v > 0 for v in train_counts.values()):
    total = sum(train_counts.values())
    weights = {i: total/(len(train_counts)*c) for i,(_,c) in enumerate(train_counts.items())}
    # Map weights to indices in 'train_gen.class_indices' to be safe
    cw = {train_gen.class_indices[cls]: w for cls, w in zip(train_counts.keys(), weights.values())}
    print("Class weights:", cw)

# ----------------
# 6) Build a solid CNN baseline
# ----------------
def conv_block(x, filters):
    x = layers.Conv2D(filters, 3, padding="same", use_bias=False)(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation("relu")(x)
    x = layers.Conv2D(filters, 3, padding="same", use_bias=False)(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation("relu")(x)
    x = layers.MaxPooling2D()(x)
    x = layers.Dropout(0.25)(x)
    return x

inputs = layers.Input(shape=IMG_SIZE+(3,))
x = layers.RandomFlip("horizontal")(inputs)
x = layers.RandomRotation(0.08)(x)
x = layers.RandomZoom(0.10)(x)
x = layers.RandomContrast(0.08)(x)

# stem
x = layers.Conv2D(32, 3, padding="same", use_bias=False)(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
# blocks
x = conv_block(x, 32)
x = conv_block(x, 64)
x = conv_block(x, 128)

x = layers.Conv2D(256, 3, padding="same", use_bias=False)(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)

x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(256, activation="relu")(x)
x = layers.Dropout(0.4)(x)

# Binary output
outputs = layers.Dense(1, activation="sigmoid")(x)

model = models.Model(inputs, outputs, name="cnn_melanoma_binary")
model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-3),
    loss="binary_crossentropy",
    metrics=["accuracy",
             tf.keras.metrics.AUC(name="auc"),
             tf.keras.metrics.Precision(name="precision"),
             tf.keras.metrics.Recall(name="recall")]
)
model.summary()


# ----------------
# 7) Callbacks
# ----------------
os.makedirs("checkpoints", exist_ok=True)
ckpt_path = os.path.join("checkpoints", "cnn_melanoma_best.keras")

callbacks = [
    ModelCheckpoint(ckpt_path, monitor="val_auc", mode="max", save_best_only=True, verbose=1),
    EarlyStopping(monitor="val_auc", mode="max", patience=6, restore_best_weights=True),
    ReduceLROnPlateau(monitor="val_loss", factor=0.3, patience=3, verbose=1, min_lr=1e-6)
]


# ----------------
# 8) Train
# ----------------
EPOCHS = 10
history = model.fit(
    train_gen,
    validation_data=test_gen,
    epochs=EPOCHS,
    callbacks=callbacks,
    class_weight=cw
)

# ----------------
# 9) Curves
# ----------------
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history["accuracy"], label="train_acc")
plt.plot(history.history["val_accuracy"], label="val_acc")
plt.title("Accuracy")
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history["loss"], label="train_loss")
plt.plot(history.history["val_loss"], label="val_loss")
plt.title("Loss")
plt.legend()
plt.tight_layout()
plt.show()



# ----------------
# 10) Evaluation: predictions, report, confusion matrix
# ----------------
y_prob = model.predict(test_gen)
y_pred = (y_prob.ravel() >= 0.5).astype(int)
y_true = test_gen.classes
target_names = [k for k,_ in sorted(test_gen.class_indices.items(), key=lambda kv: kv[1])]

print("Classification Report")
print(classification_report(y_true, y_pred, target_names=target_names, digits=4))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=target_names, yticklabels=target_names)
plt.title("Confusion Matrix")
plt.ylabel("True")
plt.xlabel("Predicted")
plt.tight_layout()
plt.show()


# ----------------
# 11) (Optional) Simple Grad-CAM for binary model
# ----------------
import numpy as np
from tensorflow.keras.preprocessing import image

def grad_cam(model, img_array, last_conv_layer_name=None):
    if last_conv_layer_name is None:
        # auto-pick last Conv2D layer
        for layer in reversed(model.layers):
            if isinstance(layer, layers.Conv2D):
                last_conv_layer_name = layer.name
                break
    grad_model = tf.keras.Model([model.inputs],
                                [model.get_layer(last_conv_layer_name).output, model.output])
    with tf.GradientTape() as tape:
        conv_out, preds = grad_model(img_array, training=False)
        class_channel = preds[:, 0]  # binary: single logit/sigmoid
    grads = tape.gradient(class_channel, conv_out)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_out = conv_out[0]
    heatmap = conv_out @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-8)
    return heatmap.numpy()

def show_grad_cam(img_path):
    img = image.load_img(img_path, target_size=IMG_SIZE)
    x = image.img_to_array(img)[None, ...] / 255.0
    heatmap = grad_cam(model, x)
    heatmap = tf.image.resize(heatmap[..., None], IMG_SIZE).numpy().squeeze()
    heatmap = np.uint8(255 * heatmap)

    plt.figure(figsize=(6,3))
    plt.subplot(1,2,1); plt.imshow(img); plt.axis('off'); plt.title("Input")
    plt.subplot(1,2,2); plt.imshow(img); plt.imshow(heatmap, alpha=0.35); plt.axis('off'); plt.title("Grad-CAM")
    plt.tight_layout(); plt.show()

    
# ================================
# 12. Save the Trained Model
# ================================
model.save("melanoma_cnn_model.h5")
print("✅ Model saved as melanoma_cnn_model.h5")


# ================================
# 13. Load the Model (if needed later)
# ================================
from tensorflow.keras.models import load_model

loaded_model = load_model("melanoma_cnn_model.h5")
print("✅ Model loaded successfully")

